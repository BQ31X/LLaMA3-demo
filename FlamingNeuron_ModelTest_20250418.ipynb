{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "120cb13e",
      "metadata": {
        "id": "120cb13e"
      },
      "outputs": [],
      "source": [
        "# üß™ FlamingNeuron Model Inference Notebook\n",
        "# Purpose: Load and test a fine-tuned, merged LLaMA 3.1 8B model from Hugging Face\n",
        "# Dependencies: Colab Pro with A100 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "48d4185c",
      "metadata": {
        "id": "48d4185c"
      },
      "outputs": [],
      "source": [
        "# üîß 1. Install Dependencies\n",
        "!pip install -qU bitsandbytes datasets accelerate loralib peft transformers trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a33cfa2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a33cfa2f",
        "outputId": "60473706-1619-49d7-909b-6ed32e0f0e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# üß† 2. Import Libraries and Check GPU\n",
        "import torch\n",
        "torch.cuda.is_available()  # Should return True if GPU is available\n",
        "\n",
        "import os\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "de19fa68",
      "metadata": {
        "id": "de19fa68"
      },
      "outputs": [],
      "source": [
        "# üî¢ 3. Configure Quantization (4-bit LoRA-style setup)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "93a9e1c2",
      "metadata": {
        "id": "93a9e1c2"
      },
      "outputs": [],
      "source": [
        "# üß† 4. Set Model ID\n",
        "HF_USER_NAME = \"FlamingNeuron\"\n",
        "model_id = f\"{HF_USER_NAME}/llama381binstruct_summarize_short_merged\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39385ad3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "05077999e97e4e218b283e9d00d1a8e6",
            "b88f655535d14893bd3956146f07be5f",
            "21a32e99489a4d95830b2d7b6b00bd65",
            "9758f8cc708c4d0a9c74911b296997c8",
            "69cda808428d494ba1dfa64a3472634b",
            "f13b27b02a814a8a9704d1e15867ec56",
            "36f0eee99aee47c199b382f81a713099",
            "462a9811a88e4409824060cb53a954fd",
            "13dea6c36b50474cbba99ccf21952d82",
            "55c4afa5b2164d5e9814a831d34367a3",
            "e71241722c524f7897af3bdc15086c93"
          ]
        },
        "id": "39385ad3",
        "outputId": "a1f68b46-d494-4a16-b577-50f34e9e5618"
      },
      "outputs": [],
      "source": [
        "# ü§ñ 5. Load Merged Model + Tokenizer from Hugging Face\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c3a04b01",
      "metadata": {
        "id": "c3a04b01"
      },
      "outputs": [],
      "source": [
        "# ‚öôÔ∏è 6. Tokenizer Setup (Recommended for Inference)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e6aa36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49e6aa36",
        "outputId": "b49360ce-5324-4cc6-cebd-04d11fb8a2e3"
      },
      "outputs": [],
      "source": [
        "# üìÇ 7. Load Legal Dataset from Tutorial\n",
        "!git clone https://github.com/lauramanor/legal_summarization\n",
        "\n",
        "import json\n",
        "jsonl_array = []\n",
        "with open('legal_summarization/tldrlegal_v1.json') as f:\n",
        "  data = json.load(f)\n",
        "  for key, value in data.items():\n",
        "    jsonl_array.append(value)\n",
        "\n",
        "from datasets import Dataset\n",
        "legal_dataset = Dataset.from_list(jsonl_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "703e1d18",
      "metadata": {
        "id": "703e1d18"
      },
      "outputs": [],
      "source": [
        "# üõ†Ô∏è 8. (Optional) Inspect the Model\n",
        "#print(model)  # Uncomment to view model architecture\n",
        "#model.config   # Uncomment to inspect config metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "FHIeKJePIhkk",
      "metadata": {
        "id": "FHIeKJePIhkk"
      },
      "outputs": [],
      "source": [
        "#9. Prompt Template\n",
        "INSTRUCTION_PROMPT_TEMPLATE = \"\"\"\\\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "Please convert the following legal content into a short human-readable summary<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "[LEGAL_DOC]{LEGAL_TEXT}[END_LEGAL_DOC]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "RESPONSE_TEMPLATE = \"\"\"\\\n",
        "{NATURAL_LANGUAGE_SUMMARY}<|eot_id|><|end_of_text|>\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8IuKzq_pIm5z",
      "metadata": {
        "id": "8IuKzq_pIm5z"
      },
      "outputs": [],
      "source": [
        "#10. Create Prompt\n",
        "def create_prompt(sample, include_response=True):\n",
        "    \"\"\"\n",
        "    Constructs a Meta-style prompt for a fine-tuned LLaMA 3 model.\n",
        "\n",
        "    - sample: a row from the legal_dataset (dict)\n",
        "    - include_response: if True, adds the summary for training-style prompts\n",
        "\n",
        "    Returns a single string.\n",
        "    \"\"\"\n",
        "    full_prompt = INSTRUCTION_PROMPT_TEMPLATE.format(LEGAL_TEXT=sample[\"original_text\"])\n",
        "    if include_response:\n",
        "        full_prompt += RESPONSE_TEMPLATE.format(NATURAL_LANGUAGE_SUMMARY=sample[\"reference_summary\"])\n",
        "    return full_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bCmwiiWLIqPF",
      "metadata": {
        "id": "bCmwiiWLIqPF"
      },
      "outputs": [],
      "source": [
        "#11. Generate response\n",
        "def generate_response(prompt, model, tokenizer):\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    model_inputs = encoded_input.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        **model_inputs,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(generated_ids)[0]\n",
        "\n",
        "    # Try to extract just the assistant response\n",
        "    parts = decoded_output.split(\"<|end_header_id|>\")\n",
        "    return parts[-1] if len(parts) > 1 else decoded_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q3DifdSSIuOi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3DifdSSIuOi",
        "outputId": "37f8f81e-f66d-40f2-e9c6-6774cb83fc01"
      },
      "outputs": [],
      "source": [
        "#12. See what the prompt looks like\n",
        "print(create_prompt(legal_dataset[1], include_response=False))\n",
        "\n",
        "# Generate a summary\n",
        "print(generate_response(create_prompt(legal_dataset[1], include_response=False), model, tokenizer))\n",
        "\n",
        "# Print the actual ground truth for comparison\n",
        "print(\"üîç Ground truth summary:\")\n",
        "print(legal_dataset[1][\"reference_summary\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d9332a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93d9332a",
        "outputId": "5b1a8884-10db-42fd-de22-2bc754f0c12f"
      },
      "outputs": [],
      "source": [
        "# ‚ú® Optional Run a Test Prompt\n",
        "prompt = \"Summarize this: The quick brown fox jumps over the lazy dog.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05077999e97e4e218b283e9d00d1a8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b88f655535d14893bd3956146f07be5f",
              "IPY_MODEL_21a32e99489a4d95830b2d7b6b00bd65",
              "IPY_MODEL_9758f8cc708c4d0a9c74911b296997c8"
            ],
            "layout": "IPY_MODEL_69cda808428d494ba1dfa64a3472634b"
          }
        },
        "13dea6c36b50474cbba99ccf21952d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21a32e99489a4d95830b2d7b6b00bd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462a9811a88e4409824060cb53a954fd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13dea6c36b50474cbba99ccf21952d82",
            "value": 2
          }
        },
        "36f0eee99aee47c199b382f81a713099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "462a9811a88e4409824060cb53a954fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c4afa5b2164d5e9814a831d34367a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cda808428d494ba1dfa64a3472634b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9758f8cc708c4d0a9c74911b296997c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c4afa5b2164d5e9814a831d34367a3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e71241722c524f7897af3bdc15086c93",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá1.22s/it]"
          }
        },
        "b88f655535d14893bd3956146f07be5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13b27b02a814a8a9704d1e15867ec56",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_36f0eee99aee47c199b382f81a713099",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "e71241722c524f7897af3bdc15086c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f13b27b02a814a8a9704d1e15867ec56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
